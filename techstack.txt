### âœ… Tech Stack for This Project:

This project is a **Django-based Sign Language Recognition System** that integrates machine learning, computer vision, and speech technologies. Here's a breakdown of the tech stack:

---

### ğŸ”§ **Backend:**
- **Python** â€” core programming language.
- **Django** â€” web framework handling routes, views, templates, forms, and ORM.
- **SQLite / PostgreSQL** â€” for storing user info, hand signs, and video references (based on Django models).
- **TensorFlow** â€” used to load and use a pre-trained model for hand sign prediction.
- **MediaPipe** â€” real-time hand tracking using computer vision.
- **SpeechRecognition (`speech_recognition`)** â€” to convert audio to text using Google API.
- **pyttsx3** â€” for text-to-speech conversion (pronunciation of predicted signs).
- **OpenCV (`cv2`)** â€” for video capture, image manipulation, and rendering predictions in real-time.
- **imageio** â€” to create videos from sequences of images.
- **shutil / os / json / tempfile** â€” for file handling and temporary data operations.

---

### ğŸ–¼ï¸ **Frontend:**
- **HTML + Django Templates** â€” dynamic rendering with `index.html`, `log_in.html`, `new_sign.html`, etc.
- **Bootstrap (likely)** â€” for styling (assumed based on standard Django projects).
- **JavaScript (possibly)** â€” for interactivity on the frontend.

---

### ğŸ” **Authentication:**
- Django's built-in authentication system (`User`, `authenticate`, `login`, `logout`, decorators like `@login_required`).

---

### ğŸ§  **Machine Learning:**
- A pre-trained hand sign recognition model is loaded from:
  ```
  Dataset/sign_language_model.h5
  ```
- Uses JSON label mappings (`label_mapping.json`, `labels_info.json`) to interpret predictions.

---

### ğŸ“ Media Handling:
- Uploaded sign images are saved in `media/hand_images`.
- Videos for sentences are stored in `media/videos`.

---

### ğŸ“‚ Modules/Files Breakdown:

- **`views.py` (this file)**: All the main functionality:
  - User login/register/logout
  - Dashboard
  - Add and train new signs
  - Capture and predict signs using webcam
  - Learn signs by converting text/speech to sign images/video

- **`verify.py`**: Handles form input validation logic.
- **`add_sign.py`**: Handles saving and formatting new sign images.
- **`training.py`**: Handles retraining the ML model with new classes.
- **`forms.py`**: Defines `HandSignForm` for Django forms.
- **`models.py`**: Defines `HandImage` and `SentenceToVideo` models for storing image/video data.

---

### ğŸ”„ Workflow Summary:

1. **Register/Login** â€” user creates an account or logs in.
2. **Dashboard** â€” user can add new signs, retrain model, or test recognition.
3. **New Sign** â€” uploads a new hand sign and saves it to the DB.
4. **Capture Sign** â€” opens webcam, uses Mediapipe + TensorFlow model to predict hand signs in real-time.
5. **Learn Sign** â€” user types or speaks a sentence, app finds images for each character and makes a slideshow-style video.

